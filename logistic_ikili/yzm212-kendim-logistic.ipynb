{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3372851,"sourceType":"datasetVersion","datasetId":2033872}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.179173Z","iopub.execute_input":"2025-03-23T11:25:46.179521Z","iopub.status.idle":"2025-03-23T11:25:46.183418Z","shell.execute_reply.started":"2025-03-23T11:25:46.179495Z","shell.execute_reply":"2025-03-23T11:25:46.182523Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sigmoid fonksiyonu: Lojistik regresyonda tahmin olasılıklarını hesaplamak için kullanılır.\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n# Lojistik Regresyon sınıfı (Gradient Descent kullanarak eğitiliyor)\nclass LogisticRegression:\n    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n        self.lr = lr                  # Öğrenme oranı\n        self.num_iter = num_iter      # İterasyon sayısı\n        self.fit_intercept = fit_intercept  # Intercept (bias) ekle\n        self.verbose = verbose        # İterasyon sırasında cost yazdırma\n    \n    # Veriye intercept (sabit terim) ekleme\n    def add_intercept(self, X):\n        intercept = np.ones((X.shape[0], 1))\n        return np.concatenate((intercept, X), axis=1)\n    \n    # Lojistik regresyonun kayıp fonksiyonu (log loss)\n    def cost_function(self, h, y):\n        return -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n    \n    # Modeli eğitim verisi üzerinde eğitme (fit)\n    def fit(self, X, y):\n        if self.fit_intercept:\n            X = self.add_intercept(X)\n        \n        # Ağırlıkları (theta) sıfırdan başlatma\n        self.theta = np.zeros(X.shape[1])\n        \n        for i in range(self.num_iter):\n            z = np.dot(X, self.theta)   # Doğrusal kombinasyon\n            h = sigmoid(z)              # Olasılık tahmini\n            gradient = np.dot(X.T, (h - y)) / y.size  # Gradyan hesaplama\n            self.theta -= self.lr * gradient          # Ağırlıkları güncelleme\n            \n            # Her 10000 adımda cost'u yazdır (isteğe bağlı)\n            if self.verbose and i % 10000 == 0:\n                print(f'Iteration {i} cost: {self.cost_function(h, y)}')\n    \n    # Tahmin olasılıklarını hesaplama\n    def predict_prob(self, X):\n        if self.fit_intercept:\n            X = self.add_intercept(X)\n        return sigmoid(np.dot(X, self.theta))\n    \n    # Sınıf tahmini (0 veya 1) yapma, eşik değeri varsayılan olarak 0.5\n    def predict(self, X, threshold=0.5):\n        return self.predict_prob(X) >= threshold\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.184608Z","iopub.execute_input":"2025-03-23T11:25:46.184846Z","iopub.status.idle":"2025-03-23T11:25:46.225600Z","shell.execute_reply.started":"2025-03-23T11:25:46.184826Z","shell.execute_reply":"2025-03-23T11:25:46.224699Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data = pd.read_excel(\"/kaggle/input/pumpkin-seeds-dataset/Pumpkin_Seeds_Dataset/Pumpkin_Seeds_Dataset.xlsx\")\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.227613Z","iopub.execute_input":"2025-03-23T11:25:46.227821Z","iopub.status.idle":"2025-03-23T11:25:46.592090Z","shell.execute_reply.started":"2025-03-23T11:25:46.227803Z","shell.execute_reply":"2025-03-23T11:25:46.591354Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Convex_Area  \\\n0     56276    888.242           326.1485           220.2388        56831   \n1     76631   1068.146           417.1932           234.2289        77280   \n2     71623   1082.987           435.8328           211.0457        72663   \n3     66458    992.051           381.5638           222.5322        67118   \n4     66107    998.146           383.8883           220.4545        67117   \n...     ...        ...                ...                ...          ...   \n2495  79637   1224.710           533.1513           190.4367        80381   \n2496  69647   1084.318           462.9416           191.8210        70216   \n2497  87994   1210.314           507.2200           222.1872        88702   \n2498  80011   1182.947           501.9065           204.7531        80902   \n2499  84934   1159.933           462.8951           234.5597        85781   \n\n      Equiv_Diameter  Eccentricity  Solidity  Extent  Roundness  \\\n0           267.6805        0.7376    0.9902  0.7453     0.8963   \n1           312.3614        0.8275    0.9916  0.7151     0.8440   \n2           301.9822        0.8749    0.9857  0.7400     0.7674   \n3           290.8899        0.8123    0.9902  0.7396     0.8486   \n4           290.1207        0.8187    0.9850  0.6752     0.8338   \n...              ...           ...       ...     ...        ...   \n2495        318.4289        0.9340    0.9907  0.4888     0.6672   \n2496        297.7874        0.9101    0.9919  0.6002     0.7444   \n2497        334.7199        0.8990    0.9920  0.7643     0.7549   \n2498        319.1758        0.9130    0.9890  0.7374     0.7185   \n2499        328.8485        0.8621    0.9901  0.7360     0.7933   \n\n      Aspect_Ration  Compactness          Class  \n0            1.4809       0.8207     Çerçevelik  \n1            1.7811       0.7487     Çerçevelik  \n2            2.0651       0.6929     Çerçevelik  \n3            1.7146       0.7624     Çerçevelik  \n4            1.7413       0.7557     Çerçevelik  \n...             ...          ...            ...  \n2495         2.7996       0.5973  Ürgüp Sivrisi  \n2496         2.4134       0.6433  Ürgüp Sivrisi  \n2497         2.2828       0.6599  Ürgüp Sivrisi  \n2498         2.4513       0.6359  Ürgüp Sivrisi  \n2499         1.9735       0.7104  Ürgüp Sivrisi  \n\n[2500 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area</th>\n      <th>Perimeter</th>\n      <th>Major_Axis_Length</th>\n      <th>Minor_Axis_Length</th>\n      <th>Convex_Area</th>\n      <th>Equiv_Diameter</th>\n      <th>Eccentricity</th>\n      <th>Solidity</th>\n      <th>Extent</th>\n      <th>Roundness</th>\n      <th>Aspect_Ration</th>\n      <th>Compactness</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56276</td>\n      <td>888.242</td>\n      <td>326.1485</td>\n      <td>220.2388</td>\n      <td>56831</td>\n      <td>267.6805</td>\n      <td>0.7376</td>\n      <td>0.9902</td>\n      <td>0.7453</td>\n      <td>0.8963</td>\n      <td>1.4809</td>\n      <td>0.8207</td>\n      <td>Çerçevelik</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>76631</td>\n      <td>1068.146</td>\n      <td>417.1932</td>\n      <td>234.2289</td>\n      <td>77280</td>\n      <td>312.3614</td>\n      <td>0.8275</td>\n      <td>0.9916</td>\n      <td>0.7151</td>\n      <td>0.8440</td>\n      <td>1.7811</td>\n      <td>0.7487</td>\n      <td>Çerçevelik</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71623</td>\n      <td>1082.987</td>\n      <td>435.8328</td>\n      <td>211.0457</td>\n      <td>72663</td>\n      <td>301.9822</td>\n      <td>0.8749</td>\n      <td>0.9857</td>\n      <td>0.7400</td>\n      <td>0.7674</td>\n      <td>2.0651</td>\n      <td>0.6929</td>\n      <td>Çerçevelik</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>66458</td>\n      <td>992.051</td>\n      <td>381.5638</td>\n      <td>222.5322</td>\n      <td>67118</td>\n      <td>290.8899</td>\n      <td>0.8123</td>\n      <td>0.9902</td>\n      <td>0.7396</td>\n      <td>0.8486</td>\n      <td>1.7146</td>\n      <td>0.7624</td>\n      <td>Çerçevelik</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66107</td>\n      <td>998.146</td>\n      <td>383.8883</td>\n      <td>220.4545</td>\n      <td>67117</td>\n      <td>290.1207</td>\n      <td>0.8187</td>\n      <td>0.9850</td>\n      <td>0.6752</td>\n      <td>0.8338</td>\n      <td>1.7413</td>\n      <td>0.7557</td>\n      <td>Çerçevelik</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>79637</td>\n      <td>1224.710</td>\n      <td>533.1513</td>\n      <td>190.4367</td>\n      <td>80381</td>\n      <td>318.4289</td>\n      <td>0.9340</td>\n      <td>0.9907</td>\n      <td>0.4888</td>\n      <td>0.6672</td>\n      <td>2.7996</td>\n      <td>0.5973</td>\n      <td>Ürgüp Sivrisi</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>69647</td>\n      <td>1084.318</td>\n      <td>462.9416</td>\n      <td>191.8210</td>\n      <td>70216</td>\n      <td>297.7874</td>\n      <td>0.9101</td>\n      <td>0.9919</td>\n      <td>0.6002</td>\n      <td>0.7444</td>\n      <td>2.4134</td>\n      <td>0.6433</td>\n      <td>Ürgüp Sivrisi</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>87994</td>\n      <td>1210.314</td>\n      <td>507.2200</td>\n      <td>222.1872</td>\n      <td>88702</td>\n      <td>334.7199</td>\n      <td>0.8990</td>\n      <td>0.9920</td>\n      <td>0.7643</td>\n      <td>0.7549</td>\n      <td>2.2828</td>\n      <td>0.6599</td>\n      <td>Ürgüp Sivrisi</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>80011</td>\n      <td>1182.947</td>\n      <td>501.9065</td>\n      <td>204.7531</td>\n      <td>80902</td>\n      <td>319.1758</td>\n      <td>0.9130</td>\n      <td>0.9890</td>\n      <td>0.7374</td>\n      <td>0.7185</td>\n      <td>2.4513</td>\n      <td>0.6359</td>\n      <td>Ürgüp Sivrisi</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>84934</td>\n      <td>1159.933</td>\n      <td>462.8951</td>\n      <td>234.5597</td>\n      <td>85781</td>\n      <td>328.8485</td>\n      <td>0.8621</td>\n      <td>0.9901</td>\n      <td>0.7360</td>\n      <td>0.7933</td>\n      <td>1.9735</td>\n      <td>0.7104</td>\n      <td>Ürgüp Sivrisi</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# encoder sınıfından nesne oluşturma\nle = LabelEncoder()\n\nfor column in data.columns:\n    if data[column].dtype == \"object\" :\n        data[f\"{column}\"] = le.fit_transform(data[f\"{column}\"])\n        print(\"This column has changed : \", column)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.593104Z","iopub.execute_input":"2025-03-23T11:25:46.593394Z","iopub.status.idle":"2025-03-23T11:25:46.599183Z","shell.execute_reply.started":"2025-03-23T11:25:46.593373Z","shell.execute_reply":"2025-03-23T11:25:46.598313Z"}},"outputs":[{"name":"stdout","text":"This column has changed :  Class\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Separate features and target (assume target is in the last column)\nX = data.iloc[:, :-1]\ny = data['Class']\n\n# Normalize only the features\nscaler = MinMaxScaler()\nX_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2,random_state=101, stratify=y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.600172Z","iopub.execute_input":"2025-03-23T11:25:46.600510Z","iopub.status.idle":"2025-03-23T11:25:46.634411Z","shell.execute_reply.started":"2025-03-23T11:25:46.600481Z","shell.execute_reply":"2025-03-23T11:25:46.633770Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = LogisticRegression()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.635162Z","iopub.execute_input":"2025-03-23T11:25:46.635382Z","iopub.status.idle":"2025-03-23T11:25:46.638606Z","shell.execute_reply.started":"2025-03-23T11:25:46.635363Z","shell.execute_reply":"2025-03-23T11:25:46.637876Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model.fit(X_train, y_train)\npredictions= model.predict(X_test)\npredictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:25:46.639327Z","iopub.execute_input":"2025-03-23T11:25:46.639554Z","iopub.status.idle":"2025-03-23T11:26:07.243404Z","shell.execute_reply.started":"2025-03-23T11:25:46.639535Z","shell.execute_reply":"2025-03-23T11:26:07.242588Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([ True,  True, False,  True,  True, False, False, False,  True,\n       False,  True, False,  True, False,  True, False,  True, False,\n        True, False,  True, False,  True,  True, False, False, False,\n       False, False,  True,  True, False, False,  True, False,  True,\n       False,  True, False, False, False, False, False, False,  True,\n        True,  True, False, False, False, False,  True,  True, False,\n       False, False,  True,  True,  True,  True,  True, False,  True,\n        True, False,  True,  True, False, False, False,  True, False,\n       False,  True, False, False, False,  True,  True, False, False,\n       False, False, False,  True,  True, False,  True, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False,  True,  True, False, False, False, False, False, False,\n       False,  True, False, False,  True, False, False,  True, False,\n        True, False, False, False, False,  True, False, False, False,\n       False,  True, False, False, False,  True, False,  True, False,\n        True, False,  True, False,  True, False, False,  True,  True,\n       False,  True,  True, False,  True,  True, False,  True, False,\n       False,  True, False, False,  True,  True, False, False, False,\n       False,  True, False, False,  True, False,  True, False,  True,\n        True,  True,  True, False, False,  True,  True,  True, False,\n        True, False, False, False,  True,  True,  True, False, False,\n        True,  True, False, False, False, False, False, False,  True,\n       False,  True, False,  True, False, False, False, False, False,\n        True,  True, False,  True,  True, False, False,  True, False,\n        True, False,  True,  True,  True, False, False,  True, False,\n       False, False,  True,  True, False, False, False, False,  True,\n        True,  True, False, False, False, False,  True, False,  True,\n       False, False, False, False, False,  True, False, False,  True,\n        True,  True, False,  True,  True,  True,  True,  True,  True,\n        True, False, False,  True, False,  True,  True,  True,  True,\n       False, False,  True, False, False,  True,  True, False,  True,\n       False, False, False,  True,  True,  True,  True, False,  True,\n       False,  True,  True, False, False, False,  True, False,  True,\n       False,  True,  True, False, False, False, False, False, False,\n        True, False,  True,  True, False,  True,  True,  True,  True,\n        True, False,  True,  True,  True, False,  True, False, False,\n        True,  True,  True, False, False,  True, False, False, False,\n       False,  True,  True,  True,  True, False,  True,  True,  True,\n        True,  True,  True, False, False, False,  True,  True, False,\n       False, False,  True, False,  True, False,  True, False, False,\n       False, False,  True, False, False,  True, False,  True, False,\n       False, False,  True, False,  True, False,  True, False, False,\n       False,  True, False, False,  True,  True,  True, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True, False,  True, False, False, False, False,  True, False,\n       False, False,  True,  True, False,  True, False,  True,  True,\n        True, False, False,  True,  True, False,  True,  True, False,\n       False,  True, False, False,  True, False,  True,  True,  True,\n       False,  True, False,  True,  True,  True,  True, False, False,\n        True,  True,  True,  True, False, False, False, False, False,\n       False, False,  True,  True,  True,  True, False,  True, False,\n       False,  True,  True,  True, False, False, False,  True, False,\n        True,  True, False, False, False,  True, False,  True,  True,\n        True,  True,  True, False, False,  True, False,  True, False,\n        True, False,  True,  True,  True, False, False,  True, False,\n        True,  True, False, False, False])"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n\n\ncm = metrics.confusion_matrix(y_test, predictions)\n\n\nprint(cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:26:21.523780Z","iopub.execute_input":"2025-03-23T11:26:21.524080Z","iopub.status.idle":"2025-03-23T11:26:21.531076Z","shell.execute_reply.started":"2025-03-23T11:26:21.524060Z","shell.execute_reply":"2025-03-23T11:26:21.530322Z"}},"outputs":[{"name":"stdout","text":"[[231  29]\n [ 37 203]]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\naccuracy = accuracy_score(y_test, predictions)\nprecision = precision_score(y_test, predictions)\nrecall = recall_score(y_test, predictions)\nf1 = f1_score(y_test, predictions)\n\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:26:24.091816Z","iopub.execute_input":"2025-03-23T11:26:24.092130Z","iopub.status.idle":"2025-03-23T11:26:24.105965Z","shell.execute_reply.started":"2025-03-23T11:26:24.092105Z","shell.execute_reply":"2025-03-23T11:26:24.105222Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.868\nPrecision: 0.875\nRecall: 0.8458333333333333\nF1 Score: 0.8601694915254238\n","output_type":"stream"}],"execution_count":21}]}